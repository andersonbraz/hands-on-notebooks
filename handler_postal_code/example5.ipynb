{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/12 15:08:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MeuApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+\n",
      "|classe     |codigo_regiao|posicao|\n",
      "+-----------+-------------+-------+\n",
      "|CLASSE 21_5|21060        |5      |\n",
      "|CLASSE 98_5|98495        |5      |\n",
      "|CLASSE 38_5|38321        |5      |\n",
      "|CLASSE 68_5|68789        |5      |\n",
      "|CLASSE 72_5|71236        |5      |\n",
      "|CLASSE 24_5|24147        |5      |\n",
      "|CLASSE 07_5|07663        |5      |\n",
      "|CLASSE 05_5|05886        |5      |\n",
      "|CLASSE 77_5|77370        |5      |\n",
      "|CLASSE 98_5|98574        |5      |\n",
      "|CLASSE 04_5|04907        |5      |\n",
      "|CLASSE 19_5|19892        |5      |\n",
      "|CLASSE 33_5|33513        |5      |\n",
      "|CLASSE 07_2|07           |2      |\n",
      "|CLASSE 05_2|05           |2      |\n",
      "|CLASSE 77_2|77           |2      |\n",
      "|CLASSE 33_2|33           |2      |\n",
      "|CLASSE 0_1 |0            |1      |\n",
      "+-----------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_classe = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"classe.csv\")\n",
    "\n",
    "df_classe.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------+----------------------------------+---------------+--------+---+---+---+----+-----+\n",
      "|id    |nome                    |email                             |data_nascimento|cep     |p_1|p_2|p_3|p_4 |p_5  |\n",
      "+------+------------------------+----------------------------------+---------------+--------+---+---+---+----+-----+\n",
      "|605755|Catarina Rios           |costelasara@example.com           |1941-07-19     |72828003|7  |72 |728|7282|72828|\n",
      "|453942|João Gabriel Nunes      |arthurdas-neves@example.org       |2004-12-01     |05055581|0  |05 |050|0505|05055|\n",
      "|264157|Sofia Araújo            |bda-costa@example.com             |1910-11-02     |30758720|3  |30 |307|3075|30758|\n",
      "|284311|Alexia Fogaça           |machadonina@example.org           |1929-01-29     |28840655|2  |28 |288|2884|28840|\n",
      "|640344|Srta. Alexia Fonseca    |joao-guilhermesousa@example.org   |2002-11-26     |85644776|8  |85 |856|8564|85644|\n",
      "|566589|Esther Correia          |vargasmateus@example.com          |1931-10-16     |16575210|1  |16 |165|1657|16575|\n",
      "|235031|Josué Moraes            |maria-sophiacaldeira@example.org  |1914-09-06     |53082954|5  |53 |530|5308|53082|\n",
      "|168517|Liz Albuquerque         |dom39@example.org                 |1984-04-18     |73321912|7  |73 |733|7332|73321|\n",
      "|963175|Gustavo Henrique Ribeiro|stella64@example.org              |1952-10-04     |34591636|3  |34 |345|3459|34591|\n",
      "|715299|Olívia Cavalcanti       |gsantos@example.org               |1997-09-23     |49474942|4  |49 |494|4947|49474|\n",
      "|660018|Arthur Pimenta          |daniela24@example.org             |1940-08-18     |77030923|7  |77 |770|7703|77030|\n",
      "|719078|Clarice Rios            |correiaana-sophia@example.org     |1959-11-10     |23847997|2  |23 |238|2384|23847|\n",
      "|287596|Samuel Porto            |ceciliavargas@example.net         |2017-07-25     |16913009|1  |16 |169|1691|16913|\n",
      "|972500|Arthur Miguel Aragão    |oferreira@example.org             |1941-09-27     |89983995|8  |89 |899|8998|89983|\n",
      "|434663|Maria Fernanda Campos   |fernandesvitor-gabriel@example.org|1942-09-08     |33513339|3  |33 |335|3351|33513|\n",
      "|598510|Liam Nogueira           |nogueiraliam@example.org          |1962-06-06     |55917059|5  |55 |559|5591|55917|\n",
      "|932291|Thales Aparecida        |luiz-henriqueda-mota@example.org  |1917-06-06     |73226672|7  |73 |732|7322|73226|\n",
      "|440365|Matheus Monteiro        |heloisamoura@example.com          |1956-04-06     |89448435|8  |89 |894|8944|89448|\n",
      "|975042|Gabrielly Siqueira      |marianasouza@example.org          |1919-09-20     |76225783|7  |76 |762|7622|76225|\n",
      "|409883|Sra. Brenda Pimenta     |bryan25@example.com               |1942-06-27     |33971818|3  |33 |339|3397|33971|\n",
      "+------+------------------------+----------------------------------+---------------+--------+---+---+---+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_fake = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"data.csv\")\\\n",
    ".withColumn(\"data_nascimento\", F.to_date(F.col(\"data_nascimento\")))\\\n",
    ".withColumn(\"cep\", F.regexp_replace(F.col(\"cep\"), \"-\", \"\"))\\\n",
    ".withColumn(\"p_1\", F.substring(F.col(\"cep\"),  1, 1))\\\n",
    ".withColumn(\"p_2\", F.substring(F.col(\"cep\"),  1, 2))\\\n",
    ".withColumn(\"p_3\", F.substring(F.col(\"cep\"),  1, 3))\\\n",
    ".withColumn(\"p_4\", F.substring(F.col(\"cep\"),  1, 4))\\\n",
    ".withColumn(\"p_5\", F.substring(F.col(\"cep\"),  1, 5))\\\n",
    "\n",
    "df_fake.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyspark.sql.functions' from '/root/hadoop/spark-3.5.1/python/pyspark/sql/functions.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_p1=df_fake.join(df_classe.alias(\"df_classe_1\"), how='left', on=(df_fake.p_1==F.col(\"df_classe_1.codigo_regiao\") )).select(df_fake.columns+[F.col(\"df_classe_1.classe\").alias(\"classe_p1\")])\n",
    "df_fake_p2=df_fake_p1.join(df_classe.alias(\"df_classe_2\"), how='left', on=(df_fake.p_2==F.col(\"df_classe_2.codigo_regiao\"))).select(df_fake_p1.columns+[F.col(\"df_classe_2.classe\").alias(\"classe_p2\")])\n",
    "df_fake_p3=df_fake_p2.join(df_classe.alias(\"df_classe_3\"), how='left', on=(df_fake.p_3==F.col(\"df_classe_3.codigo_regiao\"))).select(df_fake_p2.columns+[F.col(\"df_classe_3.classe\").alias(\"classe_p3\")])\n",
    "df_fake_p4=df_fake_p3.join(df_classe.alias(\"df_classe_4\"), how='left', on=(df_fake.p_4==F.col(\"df_classe_4.codigo_regiao\"))).select(df_fake_p3.columns+[F.col(\"df_classe_4.classe\").alias(\"classe_p4\")])\n",
    "df_fake_p5=df_fake_p4.join(df_classe.alias(\"df_classe_5\"), how='left', on=(df_fake.p_5==F.col(\"df_classe_5.codigo_regiao\"))).select(df_fake_p4.columns+[F.col(\"df_classe_5.classe\").alias(\"classe_p5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_fake_p5.select(df_fake.columns+[F.expr(\"coalesce(classe_p5,classe_p4,classe_p3,classe_p2,classe_p1)\").alias(\"classe\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+----------------------------------+---------------+--------+---+---+---+----+-----+-----------+\n",
      "|id    |nome                 |email                             |data_nascimento|cep     |p_1|p_2|p_3|p_4 |p_5  |classe     |\n",
      "+------+---------------------+----------------------------------+---------------+--------+---+---+---+----+-----+-----------+\n",
      "|812112|Benjamim Sampaio     |giovanna98@example.org            |1915-01-24     |77613170|7  |77 |776|7761|77613|CLASSE 77_2|\n",
      "|834388|Bella Melo           |cavalcantevitor@example.com       |2012-02-24     |77192882|7  |77 |771|7719|77192|CLASSE 77_2|\n",
      "|660018|Arthur Pimenta       |daniela24@example.org             |1940-08-18     |77030923|7  |77 |770|7703|77030|CLASSE 77_2|\n",
      "|409883|Sra. Brenda Pimenta  |bryan25@example.com               |1942-06-27     |33971818|3  |33 |339|3397|33971|CLASSE 33_2|\n",
      "|434663|Maria Fernanda Campos|fernandesvitor-gabriel@example.org|1942-09-08     |33513339|3  |33 |335|3351|33513|CLASSE 33_5|\n",
      "|974025|Theodoro Rios        |ana-sophiada-paz@example.org      |1989-04-01     |08535593|0  |08 |085|0853|08535|CLASSE 0_1 |\n",
      "|673293|Helena Guerra        |siqueiraclarice@example.com       |1994-03-14     |08144698|0  |08 |081|0814|08144|CLASSE 0_1 |\n",
      "|329349|Mariana Novais       |oliverda-rosa@example.com         |2020-03-14     |06827137|0  |06 |068|0682|06827|CLASSE 0_1 |\n",
      "|929896|Bernardo Vargas      |maria-ceciliapastor@example.org   |1962-10-29     |06672076|0  |06 |066|0667|06672|CLASSE 0_1 |\n",
      "|666712|Benício Câmara       |maria-sophiada-mota@example.net   |2016-11-26     |05661310|0  |05 |056|0566|05661|CLASSE 05_2|\n",
      "|215495|Camila Garcia        |mcampos@example.com               |1959-08-13     |05466609|0  |05 |054|0546|05466|CLASSE 05_2|\n",
      "|453942|João Gabriel Nunes   |arthurdas-neves@example.org       |2004-12-01     |05055581|0  |05 |050|0505|05055|CLASSE 05_2|\n",
      "|174920|Thales Costela       |britootto@example.net             |2014-12-15     |03322763|0  |03 |033|0332|03322|CLASSE 0_1 |\n",
      "|719969|Augusto Ferreira     |marianasales@example.com          |1982-11-04     |02295644|0  |02 |022|0229|02295|CLASSE 0_1 |\n",
      "+------+---------------------+----------------------------------+---------------+--------+---+---+---+----+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.filter(F.col(\"classe\").isNotNull()).orderBy(\"p_5\", ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_report = df.groupBy(\"posicao\").count()\n",
    "# df_report = df_report.orderBy(\"posicao\", ascending=False)\n",
    "# df_report.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
